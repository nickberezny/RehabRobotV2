\documentclass{article}
\author{Nicholas Berezny}
\title{Rehabilitation Robot Software Documentation}

\usepackage{cite}
\usepackage{fullpage}
\usepackage{gensymb}
\usepackage{hyperref}
\usepackage{amsmath}

\usepackage{url}[obeyspaces,spaces]

\usepackage{amsmath}
\usepackage{graphicx}
\graphicspath{ {/} }
\usepackage{svg}

\begin{document}
\maketitle
\newpage

\section{Real Time Linux}
	\subsection{Background}
	
	Real time systems are those requiring that computations be made by fixed deadlines - in other words, systems which must be deterministic. Missing deadlines may result in damage to the system or to its environment. This category can be further subdivided into soft real-time and hard real-time. Hard real-time systems usually mathematical verify that deadlines will not be missed.  For example, QNX and VxWork are both hard RTOS's. Soft real-time relaxes this condition, but still contains many of the features of a real-time system. Realtime Linux, for example. 

	Typical real time procedures include memory-locking, multi-threading, setting priorities and schedulers, and testing latencies. Memory-locking ensures that no pagefaults occur during execution, which can cause significant delays. Multi-threading is a form of parallel computing, allowing for multiple threads of computation to be run simultaneously. a scheduler will determine how many resources to delegate to each thread, based on user-set priority levels. The type of scheduler can also be changed (First-in-first-out FIFO, or Roundrobin RR).

	This software runs on a real-time enabled version of Linux which uses the PREEMPT\_RT patch to add the functionalities mentioned above. This is a soft RTOS since it is not fully deterministic, which should be adequate for this project as missed time-steps should not cause serious harm or damage.
	
		
	\subsection{Installation}
	
	The following is an outline of the installation process for a PREEMPT\_RT patched linux kernel with Ubuntu. Other linux flavours may also be used. More detailed instruction can be found at the \href{https://wiki.linuxfoundation.org/realtime/documentation/howto/applications/preemptrt_setup}{Linux Foundation Website.}
	\begin{enumerate}
		\item Download the linux kernel and the patch. The latest stable release of the patch is  4.14 (as of 11/10/2018)
		\item Patch the kernel through the command line
		\item Configure the kernel. Make sure to select "Fully Preemptible Kernel"
		\item Install the kernel on a machine running Ubuntu ....
	\end{enumerate}
	
	\subsection{Libraries}

\section{Controller}
	\subsection{Outline}
	
	
	\subsection{Initialization}
	Initialization can be found in the first few hundred lines on imp\_main.c, which calls functions found in imp\_init.c. 
	
	\begin{enumerate}
		\item TCP Socket Initialization: E.g. \href{https://www.geeksforgeeks.org/tcp-server-client-implementation-in-c/}{this tutorial}.
		\item Connecting to the DAQ: \href{https://labjack.com/support/software/api/ljm/function-reference/ljmopen}{Instructions found here}.
		\item Creating a data log text file 
		\item Initializing Mutexes: 
		\item Setting Thread Parameters and Locking Memory : \href{https://wiki.linuxfoundation.org/realtime/documentation/howto/applications/application_base}{Example here}.
	\end{enumerate}
	
	\subsection{Getting Control Parameters}
	Parameters like controller gains, desired maximum velcoity, etc can be set either using variables defined in imp\_variables.h, or by connecting to the UI and receiving custom parameters. Setting the macro CONNECT\_TO\_UI = 1 will allow the robot to connect to the UI server, and then setting GET\_PARAMS\_FROM\_UI = 1 will set control parameters based on a message from the UI.

	If getting parameters from the UI, the process will wait for a message from the UI containing the parameters. This message will being with a capital 'S'. After the system receives the message, it uses regular expression to extract parameter values. It then waits again for start message from the UI. It will then break the loop and continue executing.

	The message encodes parameter values by starting with a letter representing the parameter (e.g. the proportion gain is 'P'), followed by the value for the parameter (potentially containing a decimal point). Each parameter is separated by an underscore. For example, if the user sets the P gain to 5.1, the message will read '\_P5.1\_'.
	
	\subsection{Discretization}
	
	Control parameters can be used to construct the admittance control continuous system matrices A and B: 
	
	\begin{equation}
	\dot{X} = AX + Bf
	\end{equation}
	\[
		A=
		\begin{bmatrix}
			0 & 1 \\
			-\frac{K}{m} & -\frac{B}{m}
		\end{bmatrix}
	\]
	
	\[
		B=
		\begin{bmatrix}
			0 \\
			\frac{1}{m}
		\end{bmatrix}
	\]
	
	The equivalent discrete system can be derived from the continuous matrices:	
	
	The equivalent discrete system is:
	\begin{equation}
	X_{k+1} = A_dX_k + B_df
	\end{equation}
	\begin{equation}
	A_d = e^{At_s}
	\end{equation}
	\begin{equation} \label{eqn:bd}
	B_d = A^{-1}(A_d - I)B
	\end{equation}
	
	Where $t_s$ is the sampling time (time in seconds of a single iteration). The matrix exponential can be approximated by calculating the first $m$ terms of the series:
	
	\begin{equation} \label{eqn:matrix_exp}
	A_d ~= \sum_{n=0}^{m} \frac{A^nt_s}{n!} = I + \frac{At_s}{1} + \frac{{A}^2t_s}{2} ... 
	\end{equation}
	
	Calculation of the discrete system matrices is handled in the file \path{RehabRobot/controller/imp_math.c}, which contains the following functions relevant to discretization:
	
	\begin{itemize}
		\item \textbf{matrix\_square}: squares a given matrix and stores in another location
		\item  \textbf{factorial}: calculations the factorial of a given number
		\item  \textbf{matrix\_exp}: calculates the exponential of a matrix ($e^A$) using the series approximation in Eqn. \ref{eqn:matrix_exp}.
		\item  \textbf{invert\_matrix}: inverts a given 2x2 matrix ($A^{-1}$)
		\item  \textbf{calc\_Bd}: calculates the discrete matrix Bd using Eqn. \ref{eqn:bd}
		
	\end{itemize}
	
	\subsection{Zeroing the Force Sensor \& Homing}
	
	The motor encoder is not absolute, and so it the controller needs to determine the actuators position before continuing. This is done by homing the device, whereby it is slowly brought forward until triggering the front limit switch. This is considered position 0. At this point, the encoder is zeroed. 
	
	The homing process is comprised of a while loop, which is continually checks for contact from the front limit switch. A slow forward motor command is set constantly until the limit is triggered, which stops the motor and breaks the loop. 
	
	Next, the force sensor is zeroed. A series of readings are taken. It is important that no force be applied to the sensor during this process. The average of these readings is saved as the variable FT\_OFFSET, which is used to calibrate all raw sensor readings throughout the robots operation.
	
	\subsection{Thread 1: Controller}
	
	\subsubsection{Reading \& Writing to the DAQ}

	Communication with the DAQ is handled by the LJM library provided by LabJack. Writing and reading are handled by a single function, LJM\_ eNames().
	
	\begin{verbatim}
	LJM_eNames(daqHandle, numChannels, aNames, aWrites, aNumValues, aValues, &errorAddress);
	\end{verbatim}
	
	The function takes the following inputs:
	
	\begin{itemize}
		\item daqHandle: created during initialization
		\item numChannels: number of addresses to read/write 
		\item aNames: strings indicating the DAQ addresses to read/write
		\item aWrites: array indicating mode for each address (0=read, 1=write)
		\item aNumValues: number of values per address (in this case, always 1)
		\item aValues: array containing read data or data to be written
		\item errorAddress: contains and error codes 
	\end{itemize}
	
	There are three steps for reading and writing to DAQs: set values to be written, execute function, allocate read values to proper variables.  
	
	\subsubsection{Filtering}

	Filtering is important to reduce noise in several of the variables. Discrete Finite Impulse Response filters are used on both the force sensor and the velocity, both of which are prone to noise (either sensor noise or amplified noise due to differentiation). A finite impulse response filter is essentially a weighted average over a moving window. A custom function is used: 
	
	\begin{verbatim}
		imp_FIR(filter_array, current_value, filter_order);
	\end{verbatim}
	
	The filter\_ array contains previous filter values, current\_ value is a pointer to the current value to be filtered, and filter\_ order sets the window size (greater orders result in more aggressive filters). The filter\_ array must have a size equal to the filter\_ order.
	
	\subsubsection{Trajectory Calculation}
	\subsubsection{Admittance Control}
	\subsubsection{Maintaining Frequency}
	

	\subsection{Thread 2: Server}
	\subsubsection{TCP Socket}
	
	\subsection{Thread 3: Data Logging}
	\subsubsection{Data Formatting and Printing}
	\subsubsection{Plotting with Python}

\section{UI Server}
	\subsection{Outline}

	The purpose of the Node.js server is twofold: to serve the web application to the UI device either locally or over a local network, and to handle communication between the real time controller and the UI. The server consists of a single file, which is located at server/server.js. The following libraries/tools are used:
	
	\begin{itemize}
		\item \textbf{Node.js} as the base JS runtime environment (\href{https://nodejs.org/en/}{site})
		\item \textbf{Express} for the server framework (\href{https://expressjs.com/}{site})
		\item \textbf{Next} for server-side rendering (\href{https://nextjs.org/}{site})
		\item \textbf{Socket.io} for websocket communication (\href{https://socket.io/}{site})
	\end{itemize}
		
	\subsection{HTTP Server}

	The UI application is served using Node.js, using both Next.js (server-side rendering) and Express.js. First, Next renders the app into a static website, using Webpack among other tools. Express then servers this over a local network through the connected router. The relevant code can be found at the bottom of the server file: 
	
	\begin{verbatim}
	nextApp.prepare().then(() => {
 	 app.get('*', (req, res) => {
	    return nextHandler(req, res)
	  })
	  server.listen(ui_port, (err) => {
	    if (err) throw err
	    console.log('> Ready on http://localhost:3000')
	  })
	})
	\end{verbatim}
		
	
	\subsection{Communication}
	
	Communication is routed through the server from the controller to the UI, and vice versa. Communication with the controller is handled by a TCP Socket, whereas communication to the UI is handled by a websocket created with Socket.io. 
	
\section{UI Application}
	\subsection{Background}
	
	A variety of user interface technologies exist. An emerging trend within UI development is the use of web tools, which take advantage of already established programs like Chrome or other browsers. Frameworks like Angular, React, and Ionic can be used to build reusable UI components using familiar web utilities like HTML, Javascript, and css. 
	
	This software using React for its UI (\href{https://reactjs.org/}{site}). The UI is essentially a website which can be served and loaded in a browser like any other local site. The upside of this method is that users do not need to install anything on their device, only requiring that they know the IP address. In the future, it may be beneficial to build a native application that can be installed on a Windows machine or on a tablet. Fortunately, it is fairly easy to convert a React website to a native app, using either Electron (\href{https://electronjs.org/}{site}) for the windows app or React Native(\href{https://facebook.github.io/react-native/}{site}) for the android/iPad app. 
	
	In addition to React, the UI uses the following tools or frameworks: 
	
	\begin{itemize}
		\item \textbf{Node.js} as the base JS runtime environment (\href{https://nodejs.org/en/}{site})
		\item \textbf{Redux} for state management (\href{https://redux.js.org/}{site})
		\item \textbf{Next} for server-side rendering (\href{https://nextjs.org/}{site})
		\item \textbf{Material-UI}, a UI component library based on Google's Material Design philosophy (\href{https://material-ui.com/}{site})
		\item \textbf{Three.js} as the 3D graphics library (\href{https://threejs.org/}{site})
	\end{itemize}
	
	\subsection{Installation}
	
	First, Node.js must be installed on your system, along with the package manager npm. All other tools are then installed using npm, which can be done by either running the following command in the server folder, or by running ... in the git repository.
	
	\begin{verbatim}
	sudo npm install react react-dom redux react-redux next 
	@material-ui/core @material-ui/icons react-websocket three express
	\end{verbatim}
	
	\subsection{Structure}
	
	The UI consists of three main components: the topbar, the menu, and the content window. The content window can be used to display three more components: set up, instructions, and the visuals. 
	
	The folder tree structure is used based on the Next.js recommended setup. There are three relevant folders which will need to be accessed if you wish to change the UI: components, games, and src. 
	
	The UI consists of nested components, \textit{i.e.} components which containt multiple other components. Ultimately everything is composed of basic components such as buttons, dropdown menus, text, input text, and games/visuals. The component tree can be traced from a single overarching component (the app component) down into these basic components:
	
	\begin{figure*}[t] 
		\centering
		\includegraphics[width=0.75\linewidth]{Components}
		\caption{Nested Component Structure of the UI}
		\label{fig:VerInt}
	\end{figure*}
	
	\subsubsection{Drawer}
	
	The ``Drawer'' is the collapsible menu used to navigate between pages. It uses the DrawerList, which contains the links to each of the pages (Setup, Games, Settings). It is hidden or shown via a button. 
	
	\subsubsection{Topbar}
	
	The topbar is shown at the top of the app and contains information which is always displayed. For now it contains the menu button and the app title. 
	
	\subsubsection{Content Window}
	
	The Content window fills the space below the topbar (and to the right of the menu), and is used as a container for all other components.
	
	\subsubsection{Setup Page}
	
	The Setup page is used to change parameters for the rehabilitation session, and send them to the controller. A number of different setup pages exist, for different activities (trajectory follow, balance, etc.), for different users (developer vs therapist), and for different contexts (different experiments). The setup page contains dropdown menus, input text, and a SET button. The user must change the parameters to desired settings, and then presses the SET button to send the information to the controller and begin the session.
	
	\subsubsection{Visuals Page}
	
	The visuals page contains the required visuals for the rehabilitation session. It should be accessed after setting the session up on the Setup page. It will first contain instructions for the activity, a home button, and a run button. The home button will initiate the homing procedure on the device, after which the run button is used to begin the session. This will trigger the game/visuals to be displayed. 
	
	\subsubsection{Settings Page}
	
	The settings page is used to change user settings. Currently, there are three options: developer, user, and experiment. The developer gets direct access to control parameters (P and D gains, admittance parameters...). These parameters are set indirectly in the user setting, using more non-technical choices (\textit{e.g.} setting assistance level instead of spring stiffness). The experiment option allows one to run the structured experiment. 
	
	\subsection{Three.js \& Visuals}
	
	Three.js is a javascript library for the creation of 3D graphics for the web. It is used in the UI to create visuals and games related to the therapeutic motions to increase user engagement.
	
		\subsubsection{Scene Setup in React}
			
			Setting up the scene within React components differs from the standard Three.js tutorials. Firstly, the scene is created in the componentDidMount() function. Any object or which does not remain static in the scene must be stored in the component's state. 
	All scenes must contain some fundamental objects:
	\begin{itemize}
		\item Scene
		\item Camera
		\item Renderer 
	\end{itemize}
	First, create the scene:
	
	\begin{verbatim}
	var scene = new THREE.Scene()
	\end{verbatim}
	
	Next, create the renderer and the camera. The following code is an example -- more options are available and can be found online in the Three.js documentation. 
	
	\begin{verbatim}
	var camera = new THREE.PerspectiveCamera(90, window.innerWidth/window.innerHeight, 0.1, 800 );
	scene.add( camera );
	
	const renderer = new THREE.WebGLRenderer({ antialias: true })
	renderer.setSize(width, height)
	\end{verbatim}	
	
	Some objects have positions and orientations which can be changed, for example the position of the camera can be set as follows:
	
	\begin{verbatim}
	camera.position.set( -95,-50,30);
	camera.rotation.set(1.5,0.0,0.0);
	\end{verbatim}			
	
	Next, you create the 3D objects in your scene. Three.js provides certain geometries, like spheres, discs, planes, and blocks. For more complex objects, you will likely need to import a 3D model made from an external program (see, for example, \href{https://www.blender.org/}{Blender}). These objects also have materials, which can be single colours or more complex textures. For example, the following code creates a blue cube with a side length of 100 at the origin.  
	
	\begin{verbatim}
	var material = new THREE.MeshBasicMaterial( { color: 0x0036FF} );
	var geometry = new THREE.BoxGeometry( 100, 100, 100 );
	var cube = new THREE.Mesh( geometry, material );
	cube.position.set(0, 0, 0);
	scene.add(cube);
	\end{verbatim}
	
	The final step is to add all non-static objects to the state of the component. This includes the scene, renderer, the camera, and any objects that will move or interact during the game. 
	
	\begin{verbatim}
	this.scene = scene
	this.camera = camera
	this.renderer = renderer
	this.cube = cube
	\end{verbatim}
	
		\subsubsection{Animating the Scene}
	


\section{Controller Folder Organization}
\section{Server Folder Organization}

\section{Suggestions for Future Improvements}
	\begin{itemize}
		\item Security
		\item Handling multiple connections to the http server
		\item Improve games
	\end{itemize}


\end{document}